{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BMI3 Group5 Project4: Domain-aware aligner\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import blosum as bl\n",
    "from ICA.BMI3_domain_aware_aligner.uniprot_domain_processor import *\n",
    "mat = bl.BLOSUM(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PARSE INPUT\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_txt_to_dict(path):\n",
    "    \"\"\"\n",
    "    :param path: str path of a txt file of fasta format\n",
    "    :return: dict {id: seq, ...}\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "    fasta_dict = {}\n",
    "    curr_seq = ''\n",
    "    curr_id = None\n",
    "    for row in lines:\n",
    "        if row[0] == '>':\n",
    "            # record, except for beginning\n",
    "            if curr_id is not None:\n",
    "                fasta_dict[curr_id] = curr_seq\n",
    "            # next seq\n",
    "            curr_seq = ''\n",
    "            curr_id = row.split('|')[1]\n",
    "        else:\n",
    "            curr_seq += row.strip().replace('-', '')\n",
    "    # add last\n",
    "    fasta_dict[curr_id] = curr_seq\n",
    "    return fasta_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CORE ALGORITHM: PAIR-WISE GLOBAL ALIGNMENT WITH AFFINE GAP PENALTY\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def affine_gap_penalties_pair_wise_alignment(seq1, seq2=None, sigma=11, epsilon=1, mode='pairwise', alignment=None):\n",
    "    \"\"\"\n",
    "    :param mode: str select between 'pairwise' & 'profile' modes\n",
    "    :param seq1: str input protein sequence 1\n",
    "    :param seq2: str input protein sequence 2\n",
    "    :param sigma: int penalty for opening a gap\n",
    "    :param epsilon: int penalty for extending a gap\n",
    "    :param alignment: list of alignment strings\n",
    "    :return: tuple (align1: str alignment for seq1, align2: str alignment for seq2, score: float best alignment score)\n",
    "    \"\"\"\n",
    "    def gen_backtrack(seq1, seq2, sigma=11, epsilon=1, mode='pairwise', profile=None):\n",
    "        \"\"\"\n",
    "        :param profile: 2d nested list of profile matrix of previous alignment\n",
    "        :param mode: str select between 'pairwise' & 'profile' modes\n",
    "        :param seq1: str input protein sequence 1\n",
    "        :param seq2: str input protein sequence 2\n",
    "        :param sigma: int penalty for opening a gap\n",
    "        :param epsilon: int penalty for extending a gap\n",
    "        :return: tuple (backtracks: list [3 np.array backtracks for gap1, match, and gap2], score: float best alignment score)\n",
    "        \"\"\"\n",
    "        def weighted_score_with_profile(base, profile_column, penalty):\n",
    "            \"\"\"\n",
    "            :param base: str the base in sequence 1\n",
    "            :param profile_column: list of float the column of alignment profile matrix at corresponding position\n",
    "            :param penalty: dictionary penalty matrix\n",
    "            :return: weighted_score: float score of weighted score based on profile\n",
    "            \"\"\"\n",
    "            amino_arr = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "                     'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "            weighted_score = sum([])\n",
    "            for row in range(len(profile_column)):\n",
    "                weighted_score += penalty[base + amino_arr[row]] * profile_column[row]\n",
    "            return weighted_score\n",
    "        # init penalty\n",
    "        penalty = bl.BLOSUM(62)\n",
    "        len1 = len(seq1)\n",
    "        if mode == 'pairwise':\n",
    "            len2 = len(seq2)\n",
    "        elif mode == 'profile':\n",
    "            assert profile is not None, 'profile parameter required under profile mode!'\n",
    "            len2 = len(profile[0])\n",
    "        else:\n",
    "            assert False, 'Invalid mode! Please select from \"pairwise\" and \"profile\"!'\n",
    "        # init scores\n",
    "        match_scores = -inf * np.ones((len1+1, len2+1))\n",
    "        gap1_scores = -inf * np.ones((len1+1, len2+1))\n",
    "        gap2_scores = -inf * np.ones((len1+1, len2+1))\n",
    "        # init backtracks\n",
    "        # what are backtracks:\n",
    "        # they are matrices of the same dimension as score matrices, used to record the best previous position\n",
    "        match_back = [['' for _ in range(len2+1)] for _ in range(len1+1)]\n",
    "        gap1_back = [['' for _ in range(len2+1)] for _ in range(len1+1)]\n",
    "        gap2_back = [['' for _ in range(len2+1)] for _ in range(len1+1)]\n",
    "        # at start position, all scores are 0\n",
    "        gap1_scores[0, 0] = 0\n",
    "        gap2_scores[0, 0] = 0\n",
    "        match_scores[0, 0] = 0\n",
    "        # init first gap openings\n",
    "        gap1_scores[1, 0] = -sigma\n",
    "        gap2_scores[0, 1] = -sigma\n",
    "        match_scores[1, 0] = -sigma\n",
    "        match_scores[0, 1] = -sigma\n",
    "        # init lateral gap extensions: technically, we have 3 score matrices, we first calculate along all edges\n",
    "        for pos1 in range(2, len1 + 1):\n",
    "            gap1_scores[pos1, 0] = gap1_scores[pos1 - 1, 0] - epsilon\n",
    "            match_scores[pos1, 0] = gap1_scores[pos1, 0]\n",
    "        for pos2 in range(2, len2 + 1):\n",
    "            gap2_scores[0, pos2] = gap2_scores[0, pos2 - 1] - epsilon\n",
    "            match_scores[0, pos2] = gap2_scores[0, pos2]\n",
    "        # start dynamic traversing: technically, we start to dynamically fill in the 3 matrices\n",
    "        # unlike normal alignment, for affine gap alignment, we need 3 matrices,\n",
    "        # so for each point, we consider 3 states: in gap1, match, in gap2\n",
    "        for pos1 in range(1, len1 + 1):\n",
    "            for pos2 in range(1, len2 + 1):\n",
    "                # First, consider we are now in gap1\n",
    "                # to best get to gap 1, do we open new gap? or extend existing gap?\n",
    "                # if we extend, we move horizontally in gap1 state\n",
    "                # if we open, we move diagonally from match state to gap1 state\n",
    "                gap1_extend_score = gap1_scores[pos1 - 1, pos2] - epsilon\n",
    "                gap1_open_score = match_scores[pos1 - 1, pos2] - sigma\n",
    "                gap1_best_score = np.max([gap1_open_score, gap1_extend_score])\n",
    "                gap1_scores[pos1, pos2] = gap1_best_score\n",
    "                # if we open gap:\n",
    "                if gap1_best_score == gap1_open_score:\n",
    "                    # we record at gap1 backtrack as from match\n",
    "                    gap1_back[pos1][pos2] = 'match'\n",
    "                else:\n",
    "                    # if extend\n",
    "                    gap1_back[pos1][pos2] = 'gap1'\n",
    "                # Then, consider we are now in gap2\n",
    "                # to best get to gap 2, do we open new gap? or extend existing gap?\n",
    "                # if we extend, we move horizontally in gap2 state\n",
    "                # if we open, we move diagonally from match state to gap2 state\n",
    "                gap2_extend_score = gap2_scores[pos1, pos2 - 1] - epsilon\n",
    "                gap2_open_score = match_scores[pos1, pos2 - 1] - sigma\n",
    "                gap2_best_score = np.max([gap2_open_score, gap2_extend_score])\n",
    "                gap2_scores[pos1, pos2] = gap2_best_score\n",
    "                # if we should open gap:\n",
    "                if gap2_best_score == gap2_open_score:\n",
    "                    # we record at gap1 backtrack as from match\n",
    "                    gap2_back[pos1][pos2] = 'match'\n",
    "                else:\n",
    "                    gap2_back[pos1][pos2] = 'gap2'\n",
    "                # Last, consider we are now in match state\n",
    "                # do we continue with gaps / do a match?\n",
    "                # match_match_score = match_scores[pos1 - 1, pos2 - 1] + penalty_matrix[aa_idx[seq1[pos1-1]]][aa_idx[seq2[pos2-1]]]\n",
    "                if mode == 'pairwise':\n",
    "                    match_match_score = match_scores[pos1 - 1, pos2 - 1] + penalty[seq1[pos1-1] + seq2[pos2-1]]\n",
    "                elif mode == 'profile':\n",
    "                    # get the column to calculate weighted score from profile\n",
    "                    profile_col = [row[pos2-1] for row in profile]\n",
    "                    match_match_score = match_scores[pos1 - 1, pos2 - 1] + weighted_score_with_profile(seq1[pos1-1], profile_col, penalty)\n",
    "                best_score = np.max([gap1_best_score, match_match_score, gap2_best_score])\n",
    "                match_scores[pos1, pos2] = best_score\n",
    "                if best_score == match_match_score:\n",
    "                    match_back[pos1][pos2] = 'match'\n",
    "                elif best_score == gap2_best_score:\n",
    "                    match_back[pos1][pos2] = 'gap2'\n",
    "                elif best_score == gap1_best_score:\n",
    "                    match_back[pos1][pos2] = 'gap1'\n",
    "        return [gap1_back, match_back, gap2_back], match_scores[len1, len2]\n",
    "\n",
    "    def gen_alignment_from_backtrack(backtracks, seq1, seq2, mode='pairwise', profile=None):\n",
    "        \"\"\"\n",
    "        :param profile: 2d nested list of profile matrix of previous alignment\n",
    "        :param mode: str select between 'pairwise' & 'profile' modes\n",
    "        :param backtracks: list [3 np.array backtracks for gap1, match, and gap2]\n",
    "        :param seq1: str input protein sequence 1\n",
    "        :param seq2: str input protein sequence 2\n",
    "        :return: tuple (align1: str alignment for seq1, align2: str alignment for seq2)\n",
    "        \"\"\"\n",
    "        # start at the end of backtrack\n",
    "        pos1 = len(seq1)\n",
    "        if mode == 'pairwise':\n",
    "            pos2 = len(seq2)\n",
    "        elif mode == 'profile':\n",
    "            assert profile is not None, 'profile parameter required under profile mode!'\n",
    "            pos2 = len(profile[0])\n",
    "            # if we align to profile, seq2 will be a dummy sequence here just to record the gaps\n",
    "            seq2 = ''.join(['X' for _ in range(len(profile[0]))])\n",
    "        else:\n",
    "            assert False, 'Invalid mode! Please select from \"pairwise\" and \"profile\"!'\n",
    "        # extract backtracts\n",
    "        gap1_back, match_back, gap2_back = backtracks\n",
    "        # init alignment strings\n",
    "        align1 = ''\n",
    "        align2 = ''\n",
    "        state = 'match'  # match\n",
    "        # while not finished, we go back one step at a time\n",
    "        while pos1 > 0 or pos2 > 0:\n",
    "            # if we now in gap1\n",
    "            if state == 'gap1':\n",
    "                # if this is a gap opening, we go back to match state\n",
    "                if gap1_back[pos1][pos2] == 'match':\n",
    "                    state = 'match'\n",
    "                # we move back one step in seq1, but not seq2 because we are in gap1\n",
    "                pos1 -= 1\n",
    "                align1 += seq1[pos1]\n",
    "                align2 += '-'\n",
    "            # if we now in gap2\n",
    "            elif state == 'gap2':\n",
    "                # if this is a gap2 opening, we go back to match state\n",
    "                if gap2_back[pos1][pos2] == 'match':\n",
    "                    state = 'match'\n",
    "                # we move back one step in seq2, but not seq1 because we are in gap2\n",
    "                pos2 -= 1\n",
    "                align1 += '-'\n",
    "                align2 += seq2[pos2]\n",
    "            # if we now in match state\n",
    "            elif state == 'match':  # (this can be changed to else but less clear)\n",
    "                # what did we do last time? did we come from match / gap1 closing / gap2 closing?\n",
    "                prev_state = match_back[pos1][pos2]\n",
    "                # if we came from a match, we go back one step in BOTH seq1 and seq2\n",
    "                if prev_state == 'match':\n",
    "                    pos1 -= 1\n",
    "                    pos2 -= 1\n",
    "                    align1 += seq1[pos1]\n",
    "                    align2 += seq2[pos2]\n",
    "                # if we came from either gap, we go one step back to gap1 / gap2 state\n",
    "                elif prev_state in ['gap1', 'gap2']:  # (this can be changed to else but less clear)\n",
    "                    state = prev_state\n",
    "        # when we are at the start, we return results\n",
    "        return align1, align2\n",
    "\n",
    "    def alignment_to_profile(alignment):\n",
    "        \"\"\"\n",
    "        :param alignment: list of alignment strings\n",
    "        :return: matrix: 2d-nested list of profile matrix\n",
    "        \"\"\"\n",
    "        matrix = []\n",
    "        for base in ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "                     'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']:\n",
    "            mat = []\n",
    "            for pos in range(len(alignment[0])):\n",
    "                col = [row[pos] for row in alignment]\n",
    "                mat.append(col.count(base) / len(alignment))\n",
    "            matrix.append(mat)\n",
    "        return matrix\n",
    "    # initialize results\n",
    "    align1 = align2 = score = None\n",
    "    assert mode in ['pairwise', 'profile'], \\\n",
    "        'Invalid Mode: available modes: [pairwise, profile]'\n",
    "    if mode == 'pairwise':\n",
    "        # normal pairwise procedure\n",
    "        backtracks, score = gen_backtrack(seq1, seq2, sigma, epsilon, mode)\n",
    "        align1, align2 = gen_alignment_from_backtrack(backtracks, seq1, seq2, mode)\n",
    "    if mode == 'profile':\n",
    "        assert alignment is not None, 'alignment parameter required under \"profile\" mode!'\n",
    "        # first generate profile of the alignment\n",
    "        profile = alignment_to_profile(alignment)\n",
    "        backtracks, score = gen_backtrack(seq1, seq2, sigma, epsilon, mode, profile)\n",
    "        align1, align2 = gen_alignment_from_backtrack(backtracks, seq1, seq2, mode, profile)\n",
    "    return align1[::-1], align2[::-1], score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(DEPRECATED) GREEDY ALGO FOR MSA BASED ON PAIR-WISE GLOBAL ALIGNMENT: !NOT CONSIDERING DOMAIN!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def greedy_multiple_alignment_with_affine_gap_penalties(seqs, sigma=11, epsilon=1):\n",
    "    \"\"\"\n",
    "    :param seqs: list of str raw strings for MSA input\n",
    "    :param sigma: int penalty for opening a gap\n",
    "    :param epsilon: int penalty for extending a gap\n",
    "    :return: list of str final MSA results\n",
    "    \"\"\"\n",
    "    def init_best_pair_alignment(seqs, sigma=11, epsilon=1):\n",
    "        \"\"\"\n",
    "        :param seqs: list collection of multiple input protein sequences\n",
    "        :param sigma: int penalty for opening a gap\n",
    "        :param epsilon: int penalty for extending a gap\n",
    "        :return: tuple (best_pair: tuple best pair of sequences, best_align: list best pair-wise alignment result)\n",
    "        \"\"\"\n",
    "        best_pair = None\n",
    "        best_score = -inf\n",
    "        best_align = None\n",
    "        # iterate through all seqs to find the best pair-wise alignment\n",
    "        for pos1 in range(len(seqs) - 1):\n",
    "            for pos2 in range(pos1 + 1, len(seqs)):\n",
    "                seq1 = seqs[pos1]\n",
    "                seq2 = seqs[pos2]\n",
    "                align1, align2, curr_score = affine_gap_penalties_pair_wise_alignment(seq1, seq2, sigma, epsilon, mode='pairwise')\n",
    "                if curr_score > best_score:\n",
    "                    best_score = curr_score\n",
    "                    best_pair = (seq1, seq2)\n",
    "                    best_align = [align1, align2]\n",
    "        return best_pair, best_align\n",
    "\n",
    "    def add_one_seq_to_alignment(unaligned_seqs, alignment, sigma=11, epsilon=1):\n",
    "        \"\"\"\n",
    "        :param unaligned_seqs: list of str unaligned sequences :param alignment: list of str previous alignment sequences\n",
    "        :param sigma: int penalty for opening a gap\n",
    "        :param epsilon: int penalty for extending a gap\n",
    "        :return: tuple (unaligned_seqs: list of unaligned sequences excluding the newly added seq,\n",
    "        alignment_new: list of new alignment sequences)\n",
    "        \"\"\"\n",
    "        def update_alignment(alignment, align2_dummy):\n",
    "            \"\"\"\n",
    "            :param alignment: list of old alignment strings\n",
    "            :param align2_dummy: str align2 generated recording information about new gaps to be added in old alignments\n",
    "            :return: alignment_new: list of updated alignment strings with new gaps added\n",
    "            \"\"\"\n",
    "            alignment_new = []\n",
    "            for align in alignment:\n",
    "                align_new = ''\n",
    "                align_pos = 0\n",
    "                for pos in range(len(align2_dummy)):\n",
    "                    if align2_dummy[pos] == '-':\n",
    "                        align_new += '-'\n",
    "                    else:\n",
    "                        align_new += align[align_pos]\n",
    "                        align_pos += 1\n",
    "                alignment_new.append(align_new)\n",
    "            return alignment_new\n",
    "        # find the best seq to add to alignment\n",
    "        best_align1 = None\n",
    "        best_align2 = None\n",
    "        best_score = -inf\n",
    "        best_raw_seq = None\n",
    "        for seq in unaligned_seqs:\n",
    "            # for seq2 required in affine_gap_penalties_pair_wise_alignment we use a dummy sequence\n",
    "            align1, align2_dummy, curr_score = affine_gap_penalties_pair_wise_alignment(seq, ''.join('X' for _ in range(len(alignment[0]))),\n",
    "                                                                                        sigma, epsilon, mode='profile', alignment=alignment)\n",
    "            if curr_score > best_score:\n",
    "                best_align1 = align1\n",
    "                best_align2 = align2_dummy\n",
    "                best_score = curr_score\n",
    "                best_raw_seq = seq\n",
    "        # update the existing alignment based on new gap information recorded in align2_dummy\n",
    "        alignment_new = update_alignment(alignment, best_align2)\n",
    "        alignment_new.append(best_align1)\n",
    "        unaligned_seqs.remove(best_raw_seq)\n",
    "        return unaligned_seqs, alignment_new\n",
    "    # first, we find the pair with highest score\n",
    "    best_pair, curr_align = init_best_pair_alignment(seqs, sigma, epsilon)\n",
    "    # record aligned seqs\n",
    "    unaligned_seqs = [seq_ for seq_ in seqs if seq_ not in best_pair]\n",
    "    # while not all aligned\n",
    "    while unaligned_seqs:\n",
    "        unaligned_seqs, curr_align = add_one_seq_to_alignment(unaligned_seqs, curr_align, sigma, epsilon)\n",
    "    return curr_align"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN ALGORITHM: GREEDY MSA DOMAIN AWARE ALIGNER\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def domain_aware_greedy_MSA(all_domains, id_seq_dict, sigma=11, epsilon=1):\n",
    "    \"\"\"\n",
    "    :param all_domains: dict preconstructed dictionary from UniProt\n",
    "    :param id_seq_dict: dict {id: seq, ...}\n",
    "    :param sigma: int penalty for opening a gap\n",
    "    :param epsilon: int penalty for extending a gap\n",
    "    :return: dict {structure_identifier: {}, ...}\n",
    "    \"\"\"\n",
    "    def categorize_seqs_by_domain_info(all_domains, ids, seqs):\n",
    "        \"\"\"\n",
    "        :param all_domains: dict preconstructed dictionary from UniProt\n",
    "        :param ids: list of str UniProt IDs of seqs\n",
    "        :param seqs: list of str raw strings for MSA input\n",
    "        :return: dict {strucure_identifier: {'seqs': [sequences of this structure], 'ids': [ids of sequences]}, ...}\n",
    "        \"\"\"\n",
    "        # categorize seqs by domain structures\n",
    "        categories = {}\n",
    "        for i in range(len(ids)):\n",
    "            curr_id = ids[i]\n",
    "            curr_seq = seqs[i]\n",
    "            curr_domain_info = sequence_to_domain_structure(curr_id, curr_seq, all_domains)\n",
    "            domain_structure_list = curr_domain_info['structure_list_']\n",
    "            domain_structure_list_no_linkers = [name for name in domain_structure_list if name[-1] != '_']\n",
    "            # unique identifier of a sequence is all domain names separated by '---' Example: 'KH 1---DH---VHS' 3 domains\n",
    "            if not domain_structure_list_no_linkers:\n",
    "                structure_identifier = '_unknown_'\n",
    "            else:\n",
    "                structure_identifier = '---'.join(domain_structure_list_no_linkers)\n",
    "            if structure_identifier not in categories:\n",
    "                categories[structure_identifier] = {'seqs': [curr_seq], 'ids': [curr_id]}\n",
    "            else:\n",
    "                categories[structure_identifier]['seqs'].append(curr_seq)\n",
    "                categories[structure_identifier]['ids'].append(curr_id)\n",
    "        return categories\n",
    "\n",
    "    def split_seq_by_structure_dict(structure_dict, seq):\n",
    "        \"\"\"\n",
    "        :param structure_dict: dict generated by sequence_to_domain_structure function\n",
    "        :param seq: sequence to be split\n",
    "        :return: list of split domains & linkers (linker could be empty string)\n",
    "        \"\"\"\n",
    "        # init res\n",
    "        split_seq_list = []\n",
    "        # iterate through each domain & linker\n",
    "        structure_list_ = structure_dict['structure_list_']\n",
    "        for structure in structure_list_:\n",
    "            # start & end are 0-index, remember to use end+1 for indexing\n",
    "            start, end = structure_dict[structure]\n",
    "            split_seq_list.append(seq[start: end + 1])\n",
    "        return split_seq_list\n",
    "\n",
    "    def init_best_pair_alignment_domain_based(ids, seqs, sigma, epsilon, all_domains):\n",
    "        \"\"\"\n",
    "        :param ids: list of str UniProt IDs of seqs\n",
    "        :param all_domains: dict pre-constructed dictionary from UniProt\n",
    "        :param seqs: list collection of multiple input protein sequences\n",
    "        :param sigma: int penalty for opening a gap\n",
    "        :param epsilon: int penalty for extending a gap\n",
    "        :return: tuple (best_pair: tuple best pair of sequences, best_align: list best pair-wise alignment result)\n",
    "        \"\"\"\n",
    "        # if a single category, we return itself\n",
    "        if len(seqs) == 1:\n",
    "            return -1, seqs\n",
    "        # if not, we start to look for the best pair\n",
    "        best_pair = None\n",
    "        best_id_pair = None\n",
    "        best_score = -inf\n",
    "        best_align = None\n",
    "        # iterate through all seqs to find the best pair-wise alignment\n",
    "        for pos1 in range(len(seqs) - 1):\n",
    "            for pos2 in range(pos1 + 1, len(seqs)):\n",
    "                seq1 = seqs[pos1]\n",
    "                seq2 = seqs[pos2]\n",
    "                # use id to extract domain structure list\n",
    "                id1 = ids[pos1]\n",
    "                id2 = ids[pos2]\n",
    "                ##########\n",
    "                # print('Checking if '+id1+' and '+id2+' are best init alignment')  # testing only, output too long...\n",
    "                ##########\n",
    "                seq1_structure_dict = sequence_to_domain_structure(id1, seq1, all_domains)\n",
    "                seq2_structure_dict = sequence_to_domain_structure(id2, seq2, all_domains)\n",
    "                # split both sequences to domains & linkers, because same category, should be split in exact same way\n",
    "                seq1_split = split_seq_by_structure_dict(seq1_structure_dict, seq1)\n",
    "                seq2_split = split_seq_by_structure_dict(seq2_structure_dict, seq2)\n",
    "                ##########\n",
    "                assert len(seq1_split) == len(seq2_split), 'seq1 & seq2 are of different domain structures'\n",
    "                ##########\n",
    "                # iterate through domains & linkers, produce fragmented alignment in a list\n",
    "                final_align1 = []\n",
    "                final_align2 = []\n",
    "                # init final score, we will add curr_score of each fragment in loop below\n",
    "                final_score = 0\n",
    "                for i in range(len(seq1_split)):\n",
    "                    fragment1 = seq1_split[i]\n",
    "                    fragment2 = seq2_split[i]\n",
    "                    frag_align1, frag_align2, curr_score = affine_gap_penalties_pair_wise_alignment(fragment1, fragment2, sigma,\n",
    "                                                                                                    epsilon, mode='pairwise')\n",
    "                    final_align1.append(frag_align1)\n",
    "                    final_align2.append(frag_align2)\n",
    "                    final_score += curr_score\n",
    "                if final_score > best_score:\n",
    "                    best_score = curr_score\n",
    "                    best_id_pair = (id1, id2)\n",
    "                    best_pair = (seq1_split, seq2_split)\n",
    "                    best_align = [final_align1, final_align2]\n",
    "        ###################\n",
    "        print('Best initial pair found: '+best_id_pair[0]+', '+best_id_pair[1])\n",
    "        print(best_id_pair[0]+' and '+best_id_pair[1]+' has been aligned! '+str(len(ids)-2)+' proteins to be aligned...')\n",
    "        print('-------------------------------------------------------')\n",
    "        ###################\n",
    "        return best_pair, best_align\n",
    "\n",
    "    def add_one_seq_to_alignment_domain_based(unaligned_ids, unaligned_seqs, alignment, sigma, epsilon, all_domains):\n",
    "        \"\"\"\n",
    "        :param unaligned_seqs: list of str unaligned sequences\n",
    "        :param alignment: nested list of str fragmented previous alignment sequences\n",
    "        :param sigma: int penalty for opening a gap\n",
    "        :param epsilon: int penalty for extending a gap\n",
    "        :param all_domains: dict pre-constructed dictionary from UniProt\n",
    "        :return: tuple (unaligned_seqs: list of unaligned sequences excluding the newly added seq,\n",
    "        alignment_new: list of new alignment sequences)\n",
    "        \"\"\"\n",
    "        def update_alignment(alignment, align2_dummy, mode='string'):\n",
    "            \"\"\"\n",
    "            :param mode: str \"domain\": input list, or \"string\": input string\n",
    "            :param alignment: list of old alignment strings\n",
    "            :param align2_dummy: str align2 generated recording information about new gaps to be added in old alignments\n",
    "            :return: alignment_new: list of updated alignment strings with new gaps added\n",
    "            \"\"\"\n",
    "            assert mode in ['domain', 'string'], 'Invalid Mode! mode in update alignment must be domain or string!'\n",
    "            # alignment_new = []\n",
    "            # base case: if input is a single string, not split by domains\n",
    "            if mode == 'string':\n",
    "                # init result as 1d list\n",
    "                alignment_new = []\n",
    "                for align in alignment:\n",
    "                    align_new = ''\n",
    "                    align_pos = 0\n",
    "                    for pos in range(len(align2_dummy)):\n",
    "                        if align2_dummy[pos] == '-':\n",
    "                            align_new += '-'\n",
    "                        else:\n",
    "                            align_new += align[align_pos]\n",
    "                            align_pos += 1\n",
    "                    alignment_new.append(align_new)\n",
    "            # if input is list split by domains, we do string mode for each fragment\n",
    "            elif mode == 'domain':\n",
    "                # init result as 2d list\n",
    "                alignment_new = [[] for _ in range(len(alignment))]\n",
    "                for frag_pos in range(len(alignment[0])):\n",
    "                    # get a column in alignment\n",
    "                    curr_align_ = [align[frag_pos] for align in alignment]\n",
    "                    curr_dummy = align2_dummy[frag_pos]\n",
    "                    # for each fragment, we can use string mode to get a column\n",
    "                    new_align = update_alignment(curr_align_, curr_dummy, mode='string')\n",
    "                    # now we have 1 column, but we need to append by row\n",
    "                    for i in range(len(new_align)):\n",
    "                        alignment_new[i].append(new_align[i])\n",
    "            return alignment_new\n",
    "        # find the best seq to add to alignment\n",
    "        best_align1 = None\n",
    "        best_align2 = None\n",
    "        best_score = -inf\n",
    "        best_raw_seq = None\n",
    "        best_raw_id = None\n",
    "        for i in range(len(unaligned_seqs)):\n",
    "            curr_seq = unaligned_seqs[i]\n",
    "            curr_id = unaligned_ids[i]\n",
    "            # get domain info of this seq\n",
    "            seq_structure_dict = sequence_to_domain_structure(curr_id, curr_seq, all_domains)\n",
    "            # split this seq by domain info, this should have same structure as previous alignment\n",
    "            seq_split = split_seq_by_structure_dict(seq_structure_dict, curr_seq)\n",
    "            ##########\n",
    "            assert len(seq_split) == len(alignment[0])  # alignment is now 2d list so we use [0]\n",
    "            ##########\n",
    "            # init final score, we will add curr_score of each fragment in loop below\n",
    "            final_seq_align = []\n",
    "            final_aligment_align_dummy = []\n",
    "            final_score = 0\n",
    "            # iterate through domains & linkers, produce fragmented alignment in a list\n",
    "            for i in range(len(seq_split)):\n",
    "                # the first fragment of current sequence, a single string\n",
    "                curr_seq_frag = seq_split[i]\n",
    "                # get the first aligned fragment of all previous sequences, a list of strings\n",
    "                curr_alignment_frag = [align[i] for align in alignment]\n",
    "                # for seq2 required in affine_gap_penalties_pair_wise_alignment we use a dummy sequence\n",
    "                seq_frag_align, alignment_frag_align_dummy, curr_score = affine_gap_penalties_pair_wise_alignment(curr_seq_frag, ''.join('X' for _ in range(len(curr_alignment_frag[0]))),\n",
    "                                                                                                                  sigma, epsilon, mode='profile', alignment=curr_alignment_frag)\n",
    "                # add results for this alignment for this fragment\n",
    "                final_score += curr_score\n",
    "                final_seq_align.append(seq_frag_align)\n",
    "                final_aligment_align_dummy.append(alignment_frag_align_dummy)\n",
    "            if final_score > best_score:\n",
    "                best_align1 = final_seq_align\n",
    "                best_align2 = final_aligment_align_dummy\n",
    "                best_score = final_score\n",
    "                best_raw_seq = curr_seq\n",
    "                best_raw_id = curr_id\n",
    "        # update the existing alignment based on new gap information recorded in align2_dummy,\n",
    "        # we need dummy align2 to guide how to make gaps in previous alignments\n",
    "        alignment_new = update_alignment(alignment, best_align2, mode='domain')\n",
    "        # add this best align to the now gapped previous alignments\n",
    "        alignment_new.append(best_align1)\n",
    "        # update unaligned seqs and ids\n",
    "        # contrary to updating 2d alignments, both are 1d lists, so we can simply remove\n",
    "        unaligned_seqs.remove(best_raw_seq)\n",
    "        unaligned_ids.remove(best_raw_id)\n",
    "        ###################\n",
    "        print(best_raw_id+' has been aligned! '+str(len(unaligned_ids))+' proteins to be aligned...')\n",
    "        ###################\n",
    "        print('-------------------------------------------------------')\n",
    "        # we successfully expanded our alignment by 1!\n",
    "        return unaligned_seqs, alignment_new\n",
    "    ######################\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Domain-based Greedy MSA started...')\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Categorizing '+str(len(id_seq_dict))+' sequences')\n",
    "    ######################\n",
    "    # extract ids & seqs from input dictionary\n",
    "    ids = list(id_seq_dict.keys())\n",
    "    seqs = list(id_seq_dict.values())\n",
    "    # split seqs into categories\n",
    "    categories = categorize_seqs_by_domain_info(all_domains, ids, seqs)\n",
    "    ######################\n",
    "    print('Sequence Categorization Complete')\n",
    "    print('-------------------------------------------------------')\n",
    "    print(str(len(categories))+' distinct domain-combinations found, they are (separated by \"---\"): ')\n",
    "    for key in list(categories.keys()):\n",
    "        print(key+' : '+str(len(categories[key]['seqs']))+' sequences')\n",
    "    print('-------------------------------------------------------')\n",
    "    ######################\n",
    "    # init alignment\n",
    "    alignments = categories.copy()\n",
    "    # greedy MSA for each categories\n",
    "    for structure_identifier in categories:\n",
    "        ######################\n",
    "        print('Performing greedy MSA on '+str(len(categories[structure_identifier]['seqs']))+' sequences of structure '+structure_identifier)\n",
    "        ######################\n",
    "        # extract seqs & ids for this category\n",
    "        curr_seqs = categories[structure_identifier]['seqs']\n",
    "        curr_ids = categories[structure_identifier]['ids']\n",
    "        ######################\n",
    "        print('-------------------------------------------------------')\n",
    "        print('Looking for best initial pair...')\n",
    "        ######################\n",
    "        best_pair, curr_align = init_best_pair_alignment_domain_based(curr_ids, curr_seqs,\n",
    "                                                                      sigma, epsilon, all_domains)\n",
    "        # check if this category contains only one sequence, if so, we record itself, proceed with next category\n",
    "        if best_pair == -1:\n",
    "            alignments[structure_identifier]['category_alignment'] = curr_seqs\n",
    "            continue\n",
    "        # we join fragments together to check for unaligned seqs & ids\n",
    "        joined_best_pair = [''.join(align_arr) for align_arr in best_pair]\n",
    "        unaligned_seqs = [seq_ for seq_ in curr_seqs if seq_ not in joined_best_pair]\n",
    "        unaligned_ids = [id_ for id_ in curr_ids if id_seq_dict[id_] not in joined_best_pair]\n",
    "        # while not all aligned\n",
    "        ######################\n",
    "        if unaligned_seqs:\n",
    "            print('Extending alignment '+structure_identifier+'...')\n",
    "            print('-------------------------------------------------------')\n",
    "        ######################\n",
    "        while unaligned_seqs:\n",
    "            unaligned_seqs, curr_align = add_one_seq_to_alignment_domain_based(unaligned_ids,\n",
    "                                                                               unaligned_seqs, curr_align,\n",
    "                                                                               sigma, epsilon, all_domains)\n",
    "        # now the alignment process finished, our curr_align is still fragmented (2d list instead of 1d)\n",
    "        # IF WE WANT DIRECT OUTPUT, we concatenate fragmented alignment right now, but this cost domain information\n",
    "        # I'm not sure on 2022.11.27, so I concatenated anyway, different modes could be set later\n",
    "        concat_final_alignment = [''.join(align_list) for align_list in curr_align]\n",
    "        # record alignment for this category\n",
    "        alignments[structure_identifier]['category_alignment'] = concat_final_alignment\n",
    "    ######################\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Domain-based Greedy MSA finished!')\n",
    "    print('-------------------------------------------------------')\n",
    "    ######################\n",
    "    return alignments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYKNMWIRVMSKWVSSWYRFFLPWCYYPSVCKCEFPCTMLGEEQGIA-NLGDKISPKNKS---LINNHDQMTDNLCKYWVKNGWDM---\n",
      "YYKNM----------------LPWCYYP-----VFPCTMLGEEQGIAPPIGLKISPKNKSYDHMINNHDQETDNCCKYWVKNGYDRYPP\n",
      "226.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TEST CASES\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 2 seqs\n",
    "# two_seq_test_data_download_link = 'https://rosalind.info/problems/ba5j/'  <--------  DOWNLOAD LINK, YOU MAY NEED TO REGISTER & LOGIN\n",
    "def read_data(name):\n",
    "    with open('./rosalind_'+name+'.txt','r') as infile:\n",
    "        return infile.readlines()\n",
    "\n",
    "\n",
    "data = read_data('ba5j (2)')\n",
    "seq1 = data[0].strip()\n",
    "seq2 = data[1].strip()\n",
    "for res in affine_gap_penalties_pair_wise_alignment(seq1, seq2):\n",
    "    print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVN--------------TPLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVN--------------TPLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEDNLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n"
     ]
    }
   ],
   "source": [
    "# 3 seqs\n",
    "data = read_data('hugo')\n",
    "seq1 = data[0].strip()\n",
    "seq2 = data[1].strip()\n",
    "seq3 = data[2].strip()\n",
    "alignment = greedy_multiple_alignment_with_affine_gap_penalties([seq1, seq2, seq3])\n",
    "for align in alignment:\n",
    "    print(align)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Domain-based Greedy MSA started...\n",
      "-------------------------------------------------------\n",
      "Categorizing 25 sequences\n",
      "A0A2K5JNX9 not found in UniProt Domain Database! Proceeding as _unknown_\n",
      "Sequence Categorization Complete\n",
      "-------------------------------------------------------\n",
      "3 distinct domain-combinations found, they are (separated by \"---\"): \n",
      "SH2---SH3 1---SH3 2 : 2 sequences\n",
      "SH2---SH3 : 22 sequences\n",
      "_unknown_ : 1 sequences\n",
      "-------------------------------------------------------\n",
      "Performing greedy MSA on 2 sequences of structure SH2---SH3 1---SH3 2\n",
      "-------------------------------------------------------\n",
      "Looking for best initial pair...\n",
      "Best initial pair found: P46108, P46109\n",
      "P46108 and P46109 has been aligned! 0 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "Performing greedy MSA on 22 sequences of structure SH2---SH3\n",
      "-------------------------------------------------------\n",
      "Looking for best initial pair...\n",
      "Best initial pair found: L9LBZ5, A0A091DRT3\n",
      "L9LBZ5 and A0A091DRT3 has been aligned! 20 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "Extending alignment SH2---SH3...\n",
      "-------------------------------------------------------\n",
      "A0A7J8BWK4 has been aligned! 19 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2K5DA04 has been aligned! 18 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A8D2EJP6 has been aligned! 17 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2K5N8R6 has been aligned! 16 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A0D9RL79 has been aligned! 15 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "F7HYH0 has been aligned! 14 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2K6TEM2 has been aligned! 13 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A6J3HBX8 has been aligned! 12 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2K5S5E3 has been aligned! 11 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A6I9L5B0 has been aligned! 10 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2Y9PWG4 has been aligned! 9 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A8B8R5W8 has been aligned! 8 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A5N3WYF8 has been aligned! 7 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "G3QV45 has been aligned! 6 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A5N3WYI8 has been aligned! 5 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2U4ANU3 has been aligned! 4 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A340WZ01 has been aligned! 3 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2J8SNR0 has been aligned! 2 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A2K5RJG6 has been aligned! 1 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "A0A452DZ39 has been aligned! 0 proteins to be aligned...\n",
      "-------------------------------------------------------\n",
      "Performing greedy MSA on 1 sequences of structure _unknown_\n",
      "-------------------------------------------------------\n",
      "Looking for best initial pair...\n",
      "-------------------------------------------------------\n",
      "Domain-based Greedy MSA finished!\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# MAIN TEST: Hugo's CRK\n",
    "# parsing data & uniprot domain info\n",
    "crk_data = parse_txt_to_dict('./CRK_aln.txt')\n",
    "all_domains_crk = parse_panda_to_dict('./uniprot_crk.tsv')\n",
    "# main algorithm\n",
    "domain_alignment_result = domain_aware_greedy_MSA(all_domains_crk, crk_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputing results: \n",
      "-------------------------------------------------------\n",
      "Alignment result for 2 sequences of SH2---SH3 1---SH3 2 structure: \n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVN--------------TPLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEDNLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "-------------------------------------------------------\n",
      "Alignment result for 22 sequences of SH2---SH3 structure: \n",
      "MSSARFDSSDRSAWYMGPVSRQEAQSRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSSTPGAAINPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSSTPGAAINPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIIDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSSTPGAAINPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPSLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSSSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEDNLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEDNLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEDNLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAVTPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPSLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPSLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPIPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQNRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPSLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPIPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "MSSARFDSSDRSAWYMGPVSRQEAQNRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNR-----------------RFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPSLPTAEENLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPH------GKHGNRNSNSYGIPEPAHAYAQPQTTTPIPAVSGSPGAAVTPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDEN-E\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVILRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "M-AGNFDSEERSSWYWGRLSRQEAVALLQGQRHGVFLVRDSSTSPGDYVLSVSENSRVSHYIINSSGPRPPVPPSPAQPPPGVSPSRLRIGDQEFDSLPALLEFYKIHYLDTTTLIEPVSR-------SRQGSGVIIRQEEAEYVRALFDFNGNDEEDLPFKKGDILRIRDKPEEQWWNAEDSEGKRGMIPVPYVEKYRPASASVSALIGGNQEGSHPQPLGGPEPG-PYAQPSVNT--------------PLPNLQNGPIYARVIQKRVPNAYDKTALALEVGELVKVTKINVSGQWEGECNGKRGHFPFTHVRLLDQQNPDEDFS\n",
      "-------------------------------------------------------\n",
      "Alignment result for 1 sequences of _unknown_ structure: \n",
      "MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPGDYVLSVSENSRVSHYIINSLPNRRFKIGDQEFDHLPALLEFYKIHYLDTTTLIEPAPRYPSPPMGSVSAPNLPTAEDNLEYVRTLYDFPGNDAEDLPFKKGEILVIIEKPEEQWWSARNKDGRVGMIPVPYVEKLVRSSPHGKHGNRNSNSYGIPEPAHAYAQPQTTTPLPAVSGSPGAAITPLPSTQNGPVFAKAIQKRVPCAYDKTALALEVGDIVKVTRMNINGQWEGEVNGRKGLFPFTHVKIFDPQNPDENE\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# extracting alignments from result\n",
    "print('Outputing results: ')\n",
    "for structure in domain_alignment_result:\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Alignment result for '+str(len(domain_alignment_result[structure]['seqs']))+' sequences of '+structure+' structure: ')\n",
    "    for alignment in domain_alignment_result[structure]['category_alignment']:\n",
    "        print(alignment)\n",
    "print('-------------------------------------------------------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}